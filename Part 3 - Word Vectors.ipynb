{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model.trainables.syn1neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16731, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainables.syn1neg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, rows correspond to the number of words in vocabular and columns correspond to number of features chosen while creating word2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06483287,  0.49664444,  0.04160713, ...,  0.47206756,\n",
       "        -0.03670612, -0.32836092],\n",
       "       [ 0.06072508,  0.35780832,  0.2500123 , ...,  0.36538982,\n",
       "        -0.00081854, -0.31415913],\n",
       "       [-0.04417538,  0.45065188,  0.05245772, ...,  0.35061717,\n",
       "         0.07676341, -0.33195263],\n",
       "       ...,\n",
       "       [ 0.13201468,  0.3253682 ,  0.05130057, ...,  0.2595399 ,\n",
       "        -0.23634037, -0.5259711 ],\n",
       "       [ 0.23742779,  0.4559812 , -0.02913145, ...,  0.3378038 ,\n",
       "        -0.11888793, -0.23581652],\n",
       "       [ 0.05001378,  0.4050595 , -0.07027879, ...,  0.4548652 ,\n",
       "         0.06628785, -0.4862139 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainables.syn1neg[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.42461371e-02, -9.60368605e-04, -3.59420218e-02,  2.81621870e-02,\n",
       "       -1.16858836e-02,  4.02073376e-02, -8.47793221e-02, -8.81878138e-02,\n",
       "        1.30200461e-01,  8.16996619e-02, -8.47724918e-03,  7.71136805e-02,\n",
       "        3.28446142e-02, -6.40938953e-02,  4.06276658e-02, -1.04103964e-02,\n",
       "        5.78908883e-02, -3.41312937e-03,  1.00964561e-01, -3.34585123e-02,\n",
       "       -3.65545452e-02, -1.35103706e-04,  4.54250537e-02, -6.40790584e-03,\n",
       "       -5.22153527e-02,  5.01779132e-02,  3.13289091e-02,  4.57836092e-02,\n",
       "        9.20215994e-02, -6.66193813e-02,  1.51835475e-02, -7.45301321e-02,\n",
       "        6.73574815e-03, -1.16896788e-02, -2.17651501e-02, -4.74685803e-02,\n",
       "       -6.67587146e-02,  4.42431085e-02,  5.23999594e-02,  3.63302305e-02,\n",
       "       -9.43686888e-02,  4.70142774e-02,  9.90421027e-02, -4.05959114e-02,\n",
       "        4.88117598e-02, -2.82353647e-02,  6.33628806e-03,  7.67405331e-02,\n",
       "       -5.27671017e-02, -8.51237699e-02,  2.76257806e-02,  1.29309297e-02,\n",
       "       -6.88867271e-02,  1.18608803e-01,  1.68932676e-02,  6.88780919e-02,\n",
       "        3.83152887e-02,  2.60411650e-02, -4.41925488e-02,  4.17212732e-02,\n",
       "       -3.32165137e-02,  9.22098681e-02, -6.06370568e-02,  1.10097416e-03,\n",
       "        6.58919066e-02, -1.20139020e-02, -2.61217225e-02, -7.55935535e-02,\n",
       "       -1.78722141e-03, -5.89335850e-03, -6.08273037e-02, -5.72992042e-02,\n",
       "       -6.73771650e-02,  1.49658732e-02, -4.15994972e-03, -1.69000462e-01,\n",
       "        1.76068004e-02,  2.73802672e-02, -5.86340129e-02,  2.66331527e-02,\n",
       "       -4.64557894e-02,  3.92115340e-02,  5.31243719e-03,  7.66483471e-02,\n",
       "       -2.09938902e-02,  2.41010226e-02, -3.96704338e-02,  4.84858342e-02,\n",
       "        1.73795391e-02,  6.37580305e-02, -6.33968115e-02, -5.33818491e-02,\n",
       "        9.28332284e-03, -5.01058139e-02,  7.34860525e-02,  1.96816437e-02,\n",
       "       -9.03207529e-03, -1.43027706e-02, -1.74409747e-02, -5.21731786e-02,\n",
       "        2.06214432e-02,  5.09487055e-02, -2.86285318e-02,  1.54339317e-02,\n",
       "       -7.26057887e-02, -6.12210296e-02, -5.61476825e-03, -1.12531327e-01,\n",
       "       -5.44854179e-02,  1.18548036e-01,  1.23882659e-01, -4.10751589e-02,\n",
       "       -1.88403651e-02,  3.41775492e-02, -4.38082905e-04,  1.14200870e-02,\n",
       "       -3.81672345e-02, -2.01025773e-02,  4.78749797e-02,  8.58468562e-02,\n",
       "       -6.49029240e-02,  9.31086987e-02,  2.41517648e-02, -2.99959313e-02,\n",
       "        6.61871582e-02,  3.48708928e-02, -5.87035008e-02, -7.64218420e-02,\n",
       "       -7.40057183e-03, -1.15434304e-02, -9.80214626e-02,  4.44748215e-02,\n",
       "       -7.31607154e-02,  1.18498281e-01,  2.70886607e-02,  5.92897534e-02,\n",
       "        5.95005862e-02, -9.01649967e-02, -1.47503957e-01, -6.89789793e-03,\n",
       "       -1.87589265e-02, -3.28965113e-02,  3.52493511e-03,  3.07196341e-02,\n",
       "       -7.58576244e-02,  4.50634696e-02, -1.64564271e-02, -2.95689926e-02,\n",
       "        5.77285402e-02, -4.01807111e-03,  3.95481614e-03,  1.71328690e-02,\n",
       "       -3.63161452e-02, -6.63432758e-03, -5.51662669e-02,  7.05779865e-02,\n",
       "        3.15231383e-02,  6.79091737e-02, -1.27812788e-01, -5.95205426e-02,\n",
       "       -1.36617683e-02, -7.67431362e-03, -1.44254595e-01,  9.79221612e-02,\n",
       "       -8.99634208e-04, -2.78347470e-02,  3.19881774e-02,  9.14389151e-04,\n",
       "        6.13813959e-02, -1.12852588e-01, -2.15381831e-02,  7.08908513e-02,\n",
       "       -4.68424186e-02, -2.95790602e-02,  4.80056405e-02, -1.25131272e-02,\n",
       "       -8.39770539e-04,  6.89192861e-02, -2.67253332e-02,  7.27145597e-02,\n",
       "       -1.11323759e-01, -2.21555401e-02,  7.57850185e-02,  5.31264581e-02,\n",
       "        8.77689850e-03,  6.65818453e-02, -5.52154779e-02,  4.65461724e-02,\n",
       "        2.13249377e-03,  1.31661084e-03,  1.22502372e-01, -3.87687050e-02,\n",
       "       -6.11198284e-02,  4.56399210e-02,  4.47126403e-02, -2.28189491e-02,\n",
       "       -7.87207857e-02,  1.70698725e-02, -3.76560129e-02, -7.53253624e-02,\n",
       "       -2.28184331e-02, -5.50926179e-02,  2.71545146e-02,  8.13171044e-02,\n",
       "       -2.06285547e-02, -5.52316830e-02, -9.37138572e-02,  2.01696297e-03,\n",
       "       -6.72145141e-03, -3.06273475e-02,  6.95749372e-02,  2.40775896e-03,\n",
       "       -4.53430191e-02,  1.95159707e-02, -2.24358197e-02, -3.04510277e-02,\n",
       "        1.86261058e-01,  3.04837599e-02,  7.72496015e-02, -1.41224846e-01,\n",
       "        1.30262926e-01, -6.69533461e-02,  3.84247005e-02,  7.49680549e-02,\n",
       "        1.26745589e-02, -7.80984908e-02,  1.08351130e-02, -2.31903289e-02,\n",
       "        9.99506284e-03, -4.88020144e-02,  9.93213728e-02,  5.23554273e-02,\n",
       "        3.81121226e-02, -6.70961812e-02,  2.41078530e-02, -6.56192657e-03,\n",
       "        5.01725636e-02, -6.52865646e-03, -7.38451211e-03, -2.52855960e-02,\n",
       "        3.99896502e-02, -4.56248075e-02,  8.59311596e-02,  4.78550186e-03,\n",
       "        2.56316736e-02,  8.28601494e-02, -5.05146943e-02, -2.03338321e-02,\n",
       "        2.90123094e-02,  1.52119314e-02,  4.88480143e-02,  4.41593006e-02,\n",
       "       -6.28800914e-02,  7.61911049e-02,  2.67270883e-03, -2.83233412e-02,\n",
       "        9.78942588e-02,  1.47197200e-02,  1.42343743e-02,  6.48335740e-02,\n",
       "        3.80589403e-02,  1.00180889e-02, -1.23916775e-01, -1.36886286e-02,\n",
       "        2.05619750e-03,  4.50339681e-03, -8.38901997e-02, -4.33815233e-02,\n",
       "       -8.46261382e-02,  5.96214924e-03,  9.37865078e-02, -1.16015680e-01,\n",
       "        1.26739675e-02, -8.48583132e-02, -1.97688937e-02,  5.12711667e-02,\n",
       "       -3.98563966e-02, -4.76438701e-02,  5.44279106e-02,  1.47104962e-02,\n",
       "        1.08943805e-02,  5.95385209e-02, -2.76561752e-02,  4.60649244e-02,\n",
       "        8.30774661e-03, -1.03219105e-02, -1.51829779e-01,  9.39226821e-02,\n",
       "        1.47874877e-02, -2.76872367e-02, -5.35931215e-02, -1.48644513e-02,\n",
       "        2.78221983e-02,  4.06893156e-02, -2.74635833e-02,  2.69407351e-02,\n",
       "        2.91521028e-02, -1.13622341e-02, -7.14676008e-02,  1.05448902e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"flower\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2featureVec(words, model, nFeatures):\n",
    "    \"\"\"\n",
    "    Takes words, model and number of features as input and converts the review into 1xnFeatures dimension by\n",
    "    averaging the weight of the words present in the review and vocabulary of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    featureVec = np.zeros((nFeatures), dtype = 'float32')\n",
    "    nWords = 0\n",
    "    \n",
    "    #converting to set to make searching faster\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for w in words:\n",
    "        if(w in index2word_set):\n",
    "            nWords += 1\n",
    "            featureVec = np.add(featureVec, model.wv[w])\n",
    "    \n",
    "    return np.divide(featureVec, nWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformFeatureReview(reviews, model, nFeatures):\n",
    "    \"\"\"\n",
    "    Takes a set of reviews, the model and number of features and converts each review into a uniform feature\n",
    "    matrix of 1 x nFeatures dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    AvgReview = np.zeros((len(reviews), nFeatures), dtype = 'float32')\n",
    "    counter = 0\n",
    "    \n",
    "    for review in reviews:\n",
    "        if(counter % 1000 == 0):\n",
    "            print('Review number: ' + str(counter) + ' of ' + str(len(reviews)) + ' reviews')\n",
    "        AvgReview[counter] = convert2featureVec(review, model, nFeatures)\n",
    "        counter += 1\n",
    "    \n",
    "    return AvgReview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we transform our reviews into a uniform shape using the functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word2vec\n",
    "from word2vec import transformSentence\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('labeledTrainData.tsv', header = 0, delimiter='\\t', quoting = 3)\n",
    "test = pd.read_csv('testData.tsv', header = 0, delimiter='\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning train reviews...\n",
      "Review number: 0 of 25000 reviews\n",
      "Review number: 1000 of 25000 reviews\n",
      "Review number: 2000 of 25000 reviews\n",
      "Review number: 3000 of 25000 reviews\n",
      "Review number: 4000 of 25000 reviews\n",
      "Review number: 5000 of 25000 reviews\n",
      "Review number: 6000 of 25000 reviews\n",
      "Review number: 7000 of 25000 reviews\n",
      "Review number: 8000 of 25000 reviews\n",
      "Review number: 9000 of 25000 reviews\n",
      "Review number: 10000 of 25000 reviews\n",
      "Review number: 11000 of 25000 reviews\n",
      "Review number: 12000 of 25000 reviews\n",
      "Review number: 13000 of 25000 reviews\n",
      "Review number: 14000 of 25000 reviews\n",
      "Review number: 15000 of 25000 reviews\n",
      "Review number: 16000 of 25000 reviews\n",
      "Review number: 17000 of 25000 reviews\n",
      "Review number: 18000 of 25000 reviews\n",
      "Review number: 19000 of 25000 reviews\n",
      "Review number: 20000 of 25000 reviews\n",
      "Review number: 21000 of 25000 reviews\n",
      "Review number: 22000 of 25000 reviews\n",
      "Review number: 23000 of 25000 reviews\n",
      "Review number: 24000 of 25000 reviews\n",
      "Cleaning test reviews...\n",
      "Review number: 0 of 25000 reviews\n",
      "Review number: 1000 of 25000 reviews\n",
      "Review number: 2000 of 25000 reviews\n",
      "Review number: 3000 of 25000 reviews\n",
      "Review number: 4000 of 25000 reviews\n",
      "Review number: 5000 of 25000 reviews\n",
      "Review number: 6000 of 25000 reviews\n",
      "Review number: 7000 of 25000 reviews\n",
      "Review number: 8000 of 25000 reviews\n",
      "Review number: 9000 of 25000 reviews\n",
      "Review number: 10000 of 25000 reviews\n",
      "Review number: 11000 of 25000 reviews\n",
      "Review number: 12000 of 25000 reviews\n",
      "Review number: 13000 of 25000 reviews\n",
      "Review number: 14000 of 25000 reviews\n",
      "Review number: 15000 of 25000 reviews\n",
      "Review number: 16000 of 25000 reviews\n",
      "Review number: 17000 of 25000 reviews\n",
      "Review number: 18000 of 25000 reviews\n",
      "Review number: 19000 of 25000 reviews\n",
      "Review number: 20000 of 25000 reviews\n",
      "Review number: 21000 of 25000 reviews\n",
      "Review number: 22000 of 25000 reviews\n",
      "Review number: 23000 of 25000 reviews\n",
      "Review number: 24000 of 25000 reviews\n"
     ]
    }
   ],
   "source": [
    "clean_train_reviews = []\n",
    "nFeatures = 300\n",
    "\n",
    "print('Cleaning train reviews...')\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append(transformSentence(review, remove_stopwords=True))\n",
    "\n",
    "trainVec = transformFeatureReview(clean_train_reviews, model, nFeatures)\n",
    "\n",
    "print('Cleaning test reviews...')\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append(transformSentence(review, remove_stopwords= True))\n",
    "\n",
    "testVec = transformFeatureReview(clean_test_reviews, model, nFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling a classifier\n",
    "#### Here we use random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreya/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearnrn.ensemble import RandomForestClassifier as rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF = rfc(n_estimators=100)\n",
    "\n",
    "# train\n",
    "RF = RF.fit(trainVec, train[\"sentiment\"])\n",
    "\n",
    "# predict\n",
    "result = RF.predict(testVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data = {'id': test['id'], \"sentiment\" : result})\n",
    "output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
